{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1V6LllmSd_v",
        "outputId": "503a2cf3-ac31-4c49-a5f1-27b5e95f27db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.171.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, docx2txt, python-docx, PyPDF2, langchain-google-genai\n",
            "Successfully installed PyPDF2-3.0.1 docx2txt-0.9 filetype-1.2.0 langchain-google-genai-2.0.10 python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install google-generativeai PyPDF2 python-docx docx2txt langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import PyPDF2\n",
        "import docx2txt\n",
        "from docx import Document\n",
        "import io\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import json\n",
        "import re\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "E14GrSXVTneM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Gemini API using Colab Secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # Get API key from Colab secrets\n",
        "    API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=API_KEY)\n",
        "\n",
        "    # Initialize the model with Gemini 1.5 Flash (free tier)\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    print(\"‚úÖ Gemini API configured successfully with gemini-1.5-flash!\")\n",
        "    print(\"‚úÖ API key loaded from Colab secrets\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"\\nüîß Setup Instructions:\")\n",
        "    print(\"1. Go to the left sidebar in Colab\")\n",
        "    print(\"2. Click on the üîë key icon (Secrets)\")\n",
        "    print(\"3. Click 'Add new secret'\")\n",
        "    print(\"4. Name: GOOGLE_API_KEY\")\n",
        "    print(\"5. Value: Your Gemini API key from https://aistudio.google.com/app/apikey\")\n",
        "    print(\"6. Toggle 'Notebook access' ON\")\n",
        "    print(\"7. Re-run this cell\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsp9e1M-Tq7A",
        "outputId": "4f04c364-6d3a-43f9-8bc7-ded893dfb6cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gemini API configured successfully with gemini-1.5-flash!\n",
            "‚úÖ API key loaded from Colab secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StudyAssistant:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_file):\n",
        "        \"\"\"Extract text from uploaded PDF file\"\"\"\n",
        "        try:\n",
        "            reader = PyPDF2.PdfReader(pdf_file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading PDF: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_text_from_docx(self, docx_file):\n",
        "        \"\"\"Extract text from uploaded Word document\"\"\"\n",
        "        try:\n",
        "            # Method 1: Using docx2txt (simpler and more reliable)\n",
        "            text = docx2txt.process(docx_file)\n",
        "            if text:\n",
        "                return text\n",
        "\n",
        "            # Method 2: Using python-docx as fallback\n",
        "            docx_file.seek(0)  # Reset file pointer\n",
        "            doc = Document(docx_file)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\n\"\n",
        "\n",
        "            # Also extract text from tables\n",
        "            for table in doc.tables:\n",
        "                for row in table.rows:\n",
        "                    for cell in row.cells:\n",
        "                        text += cell.text + \" \"\n",
        "                    text += \"\\n\"\n",
        "\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading Word document: {e}\")\n",
        "            return None\n",
        "\n",
        "    def detect_file_type(self, filename):\n",
        "        \"\"\"Detect file type based on extension\"\"\"\n",
        "        filename = filename.lower()\n",
        "        if filename.endswith('.pdf'):\n",
        "            return 'pdf'\n",
        "        elif filename.endswith(('.docx', '.doc')):\n",
        "            return 'docx'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "    def extract_text_from_file(self, file_content, filename):\n",
        "        \"\"\"Extract text from any supported file format\"\"\"\n",
        "        file_type = self.detect_file_type(filename)\n",
        "        file_obj = io.BytesIO(file_content)\n",
        "\n",
        "        if file_type == 'pdf':\n",
        "            return self.extract_text_from_pdf(file_obj)\n",
        "        elif file_type == 'docx':\n",
        "            return self.extract_text_from_docx(file_obj)\n",
        "        else:\n",
        "            print(f\"‚ùå Unsupported file type: {filename}\")\n",
        "            print(\"üìã Supported formats: PDF (.pdf), Word (.docx, .doc)\")\n",
        "            return None\n",
        "\n",
        "    def summarize_content(self, content: str) -> str:\n",
        "        \"\"\"Summarize the study material into key points\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "Please summarize the following study material into concise bullet points that capture the key concepts and important information:\n",
        "\n",
        "Study Material:\n",
        "{content}\n",
        "\n",
        "Instructions:\n",
        "- Create 5-8 clear, concise bullet points\n",
        "- Focus on the most important concepts\n",
        "- Each point should be 1-2 sentences maximum\n",
        "- Use simple, clear language\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating summary: {e}\")\n",
        "            return \"Unable to generate summary\"\n",
        "\n",
        "    def generate_quiz_questions(self, content: str, num_questions: int = 5) -> List[Dict]:\n",
        "        \"\"\"Generate multiple-choice quiz questions based on the content\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "Based on the following study material, create {num_questions} multiple-choice quiz questions.\n",
        "\n",
        "Study Material:\n",
        "{content}\n",
        "\n",
        "Instructions:\n",
        "- Create {num_questions} multiple-choice questions\n",
        "- Each question should have 4 options (a, b, c, d)\n",
        "- Questions should test understanding of key concepts\n",
        "- Include the correct answer for each question\n",
        "- Vary the difficulty from basic recall to application\n",
        "- Format each question clearly\n",
        "\n",
        "Please format your response as follows for each question:\n",
        "Question X: [Question text]\n",
        "a) [Option A]\n",
        "b) [Option B]\n",
        "c) [Option C]\n",
        "d) [Option D]\n",
        "Correct Answer: [Letter]\n",
        "Explanation: [Brief explanation]\n",
        "\n",
        "Quiz Questions:\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return self._parse_quiz_response(response.text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating quiz: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_quiz_response(self, response_text: str) -> List[Dict]:\n",
        "        \"\"\"Parse the quiz response into structured format\"\"\"\n",
        "        questions = []\n",
        "        question_blocks = re.split(r'Question \\d+:', response_text)[1:]  # Skip first empty element\n",
        "\n",
        "        for i, block in enumerate(question_blocks, 1):\n",
        "            try:\n",
        "                lines = block.strip().split('\\n')\n",
        "                question_text = lines[0].strip()\n",
        "\n",
        "                options = {}\n",
        "                correct_answer = \"\"\n",
        "                explanation = \"\"\n",
        "\n",
        "                for line in lines[1:]:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith(('a)', 'b)', 'c)', 'd)')):\n",
        "                        key = line[0]\n",
        "                        value = line[3:].strip()\n",
        "                        options[key] = value\n",
        "                    elif line.startswith('Correct Answer:'):\n",
        "                        correct_answer = line.split(':')[1].strip().lower()\n",
        "                    elif line.startswith('Explanation:'):\n",
        "                        explanation = line.split(':', 1)[1].strip()\n",
        "\n",
        "                if question_text and options and correct_answer:\n",
        "                    questions.append({\n",
        "                        'question': question_text,\n",
        "                        'options': options,\n",
        "                        'correct_answer': correct_answer,\n",
        "                        'explanation': explanation\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing question {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return questions\n",
        "\n",
        "    def display_quiz(self, questions: List[Dict]):\n",
        "        \"\"\"Display quiz questions in a user-friendly format\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"üìö GENERATED QUIZ QUESTIONS\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        for i, q in enumerate(questions, 1):\n",
        "            print(f\"\\nüîπ Question {i}: {q['question']}\")\n",
        "            print()\n",
        "            for key, value in q['options'].items():\n",
        "                print(f\"   {key}) {value}\")\n",
        "            print(f\"\\n‚úÖ Correct Answer: {q['correct_answer'].upper()}\")\n",
        "            if q['explanation']:\n",
        "                print(f\"üí° Explanation: {q['explanation']}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "# Initialize the Study Assistant\n",
        "study_assistant = StudyAssistant(model)\n",
        "print(\"‚úÖ Study Assistant initialized successfully!\")\n",
        "print(\"üìã Supported file formats: PDF (.pdf), Word (.docx, .doc)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSDNran0UMrt",
        "outputId": "ca600b81-3f56-4b06-e550-3384aa5a029c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Study Assistant initialized successfully!\n",
            "üìã Supported file formats: PDF (.pdf), Word (.docx, .doc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_process_file():\n",
        "    \"\"\"Upload and process PDF or Word document\"\"\"\n",
        "    print(\"üìÅ Please upload your study material:\")\n",
        "    print(\"üìã Supported formats: PDF (.pdf), Word (.docx, .doc)\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"‚ùå No file uploaded\")\n",
        "        return None, None\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    file_content = uploaded[filename]\n",
        "\n",
        "    print(f\"‚úÖ File uploaded: {filename}\")\n",
        "    print(f\"üìä File size: {len(file_content)} bytes\")\n",
        "\n",
        "    # Detect and process the file\n",
        "    text = study_assistant.extract_text_from_file(file_content, filename)\n",
        "\n",
        "    if text:\n",
        "        text = text.strip()\n",
        "        if len(text) < 50:\n",
        "            print(\"‚ö†Ô∏è  Warning: Extracted text is very short. Please check if the file contains readable text.\")\n",
        "\n",
        "        word_count = len(text.split())\n",
        "        print(f\"‚úÖ Successfully extracted {len(text)} characters ({word_count} words)\")\n",
        "\n",
        "        # Show preview of extracted text\n",
        "        preview = text[:200] + \"...\" if len(text) > 200 else text\n",
        "        print(f\"\\nüìñ Text preview:\\n{preview}\")\n",
        "\n",
        "        return text, filename\n",
        "    else:\n",
        "        print(\"‚ùå Failed to extract text from file\")\n",
        "        print(\"üîß Troubleshooting tips:\")\n",
        "        print(\"   - Ensure the file is not password protected\")\n",
        "        print(\"   - Check if the file contains readable text (not just images)\")\n",
        "        print(\"   - Try a different file format\")\n",
        "        return None, None\n",
        "\n",
        "def process_text_input():\n",
        "    \"\"\"Process text input directly\"\"\"\n",
        "    print(\"üìù Enter your study material (paste text below):\")\n",
        "    print(\"üí° Tip: You can paste content from any source\")\n",
        "    print(\"Type 'END' on a new line when finished:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    lines = []\n",
        "    while True:\n",
        "        try:\n",
        "            line = input()\n",
        "            if line.strip().upper() == 'END':\n",
        "                break\n",
        "            lines.append(line)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n‚ùå Input cancelled\")\n",
        "            return None\n",
        "\n",
        "    text = '\\n'.join(lines).strip()\n",
        "    if text:\n",
        "        word_count = len(text.split())\n",
        "        print(f\"‚úÖ Successfully captured {len(text)} characters ({word_count} words)\")\n",
        "        return text\n",
        "    else:\n",
        "        print(\"‚ùå No text provided\")\n",
        "        return None\n",
        "\n",
        "def validate_content(text):\n",
        "    \"\"\"Validate if the content is suitable for quiz generation\"\"\"\n",
        "    if not text or len(text.strip()) < 50:\n",
        "        print(\"‚ö†Ô∏è  Content is too short for effective quiz generation.\")\n",
        "        print(\"üí° Please provide at least a few sentences of study material.\")\n",
        "        return False\n",
        "\n",
        "    word_count = len(text.split())\n",
        "    if word_count < 20:\n",
        "        print(\"‚ö†Ô∏è  Content has very few words. Quiz quality may be limited.\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "print(\"‚úÖ Enhanced upload and processing functions ready!\")\n",
        "print(\"üìã Supported formats: PDF, Word documents, and direct text input\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUJBOEkmUoqN",
        "outputId": "d75f9c37-50db-467b-8696-a8d1368eb1ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Enhanced upload and processing functions ready!\n",
            "üìã Supported formats: PDF, Word documents, and direct text input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_study_assistant():\n",
        "    \"\"\"Main function to run the study assistant\"\"\"\n",
        "    print(\"üéì Welcome to the Study Assistant Quiz Generator!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Choose input method\n",
        "    print(\"\\nChoose your input method:\")\n",
        "    print(\"1. Upload PDF file\")\n",
        "    print(\"2. Enter text directly\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "\n",
        "    study_material = None\n",
        "\n",
        "    if choice == '1':\n",
        "        study_material, filename = upload_and_process_file()\n",
        "    elif choice == '2':\n",
        "        study_material = process_text_input()\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice. Please run again.\")\n",
        "        return\n",
        "\n",
        "    if not study_material:\n",
        "        print(\"‚ùå No study material to process. Please try again.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üìã GENERATING SUMMARY...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Generate summary\n",
        "    summary = study_assistant.summarize_content(study_material)\n",
        "    print(summary)\n",
        "\n",
        "    # Ask for number of questions\n",
        "    while True:\n",
        "        try:\n",
        "            num_questions = int(input(f\"\\nü§î How many quiz questions would you like? (1-10): \"))\n",
        "            if 1 <= num_questions <= 10:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a number between 1 and 10.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a valid number.\")\n",
        "\n",
        "    print(f\"\\n‚è≥ Generating {num_questions} quiz questions...\")\n",
        "\n",
        "    # Generate quiz questions\n",
        "    questions = study_assistant.generate_quiz_questions(study_material, num_questions)\n",
        "\n",
        "    if questions:\n",
        "        study_assistant.display_quiz(questions)\n",
        "\n",
        "        # Option to save results\n",
        "        save_choice = input(f\"\\nüíæ Would you like to save the quiz to a file? (y/n): \").strip().lower()\n",
        "        if save_choice == 'y':\n",
        "            save_quiz_to_file(summary, questions)\n",
        "    else:\n",
        "        print(\"‚ùå Failed to generate quiz questions. Please try again.\")\n",
        "\n",
        "def save_quiz_to_file(summary, questions):\n",
        "    \"\"\"Save quiz results to a text file\"\"\"\n",
        "    filename = f\"quiz_results.txt\"\n",
        "\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"STUDY MATERIAL SUMMARY\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\")\n",
        "        f.write(summary + \"\\n\\n\")\n",
        "\n",
        "        f.write(\"QUIZ QUESTIONS\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "        for i, q in enumerate(questions, 1):\n",
        "            f.write(f\"Question {i}: {q['question']}\\n\")\n",
        "            for key, value in q['options'].items():\n",
        "                f.write(f\"   {key}) {value}\\n\")\n",
        "            f.write(f\"Correct Answer: {q['correct_answer'].upper()}\\n\")\n",
        "            if q['explanation']:\n",
        "                f.write(f\"Explanation: {q['explanation']}\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "    print(f\"‚úÖ Quiz saved to {filename}\")\n",
        "    files.download(filename)\n",
        "\n",
        "print(\"‚úÖ Main application interface ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHwu1cgOVMRz",
        "outputId": "3514908e-0ff6-4152-9d8c-6583fed6f6dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Main application interface ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Study Assistant\n",
        "run_study_assistant()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5cXgW840VVTP",
        "outputId": "364a8596-b697-4a17-f48b-9c841ed11e68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéì Welcome to the Study Assistant Quiz Generator!\n",
            "============================================================\n",
            "\n",
            "Choose your input method:\n",
            "1. Upload PDF file\n",
            "2. Enter text directly\n",
            "\n",
            "Enter your choice (1 or 2): 1\n",
            "üìÅ Please upload your study material:\n",
            "üìã Supported formats: PDF (.pdf), Word (.docx, .doc)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cef2be79-8cb4-4f7d-a719-13d705040481\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cef2be79-8cb4-4f7d-a719-13d705040481\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Day-2-business-report.pdf to Day-2-business-report.pdf\n",
            "‚úÖ File uploaded: Day-2-business-report.pdf\n",
            "üìä File size: 419957 bytes\n",
            "‚úÖ Successfully extracted 38229 characters (4005 words)\n",
            "\n",
            "üìñ Text preview:\n",
            "Assignment\n",
            " \n",
            "of\n",
            " \n",
            "Prompt\n",
            " \n",
            "Engineering\n",
            " \n",
            " \n",
            "Topics\n",
            " \n",
            ":\n",
            " \n",
            "‚Äú\n",
            "Create\n",
            " \n",
            "and\n",
            " \n",
            "Validate\n",
            " \n",
            "Your\n",
            " \n",
            "Business\n",
            " \n",
            "Plan\n",
            " \n",
            "with\n",
            " \n",
            "Gener ative\n",
            " \n",
            "AI\n",
            "‚Äù\n",
            " \n",
            " \n",
            "Date:\n",
            " \n",
            "10-06-2025\n",
            " \n",
            " \n",
            "AI\n",
            " \n",
            "Agentic\n",
            " \n",
            ":\n",
            " \n",
            "Perplexity\n",
            " \n",
            " \n",
            "Prom...\n",
            "\n",
            "============================================================\n",
            "üìã GENERATING SUMMARY...\n",
            "============================================================\n",
            "* The study focuses on creating and validating low-budget AI healthcare startup ideas for Tier-2 Indian cities.  These leverage generative AI and require only basic tech skills.\n",
            "\n",
            "* Three AI healthcare business ideas were validated: a multilingual mental health chatbot, an AI-powered personalized meal planner for chronic patients, and an AI medical transcription service for clinics.\n",
            "\n",
            "* Validation considered problem-solution fit, market demand (using data from NASSCOM, FICCI, etc.), existing competition, differentiation strategies, and low-budget feasibility.\n",
            "\n",
            "* A comprehensive business plan was developed for the virtual mental health chatbot, detailing market analysis, target customers, business model, technology stack, and a budget under ‚Çπ1 lakh.\n",
            "\n",
            "* The chatbot plan emphasizes affordability, accessibility via WhatsApp and mobile apps, and culturally relevant content in local languages (Tamil, Malayalam, Hindi).\n",
            "\n",
            "*  All three validated ideas align with Indian government initiatives (Ayushman Bharat Digital Mission, National Tele-Mental Health Program) promoting digital healthcare in underserved areas.\n",
            "\n",
            "\n",
            "ü§î How many quiz questions would you like? (1-10): 6\n",
            "\n",
            "‚è≥ Generating 6 quiz questions...\n",
            "============================================================\n",
            "üìö GENERATED QUIZ QUESTIONS\n",
            "============================================================\n",
            "\n",
            "üîπ Question 1: What is the primary constraint for the AI healthcare business ideas outlined in the study material?\n",
            "\n",
            "   a) High technical skill requirements\n",
            "   b) Extensive marketing budget\n",
            "   c) Limited access to AI tools\n",
            "   d) Low budget (under ‚Çπ1 lakh investment)\n",
            "\n",
            "‚úÖ Correct Answer: D)\n",
            "üí° Explanation: The study material explicitly states that all ideas must be feasible with a budget under ‚Çπ1 lakh.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 2: Which of the following AI healthcare business ideas is NOT specifically designed for remote or online-first operation?\n",
            "\n",
            "   a) AI-Powered Symptom Checker Chatbot\n",
            "   b) Remote Medication Reminder & Adherence Service\n",
            "   c) AI-Powered Health Content Generator\n",
            "   d) AI Medical Transcription Service for Local Clinics\n",
            "\n",
            "‚úÖ Correct Answer: D)\n",
            "üí° Explanation: While the transcription service can be *done* remotely, the output is ultimately intended for use in physical clinics.  The other options are all explicitly remote-first.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 3: The study material emphasizes the importance of which factor for successful AI healthcare startups in Tier-2 Indian cities?\n",
            "\n",
            "   a) English language proficiency\n",
            "   b) Advanced technical expertise\n",
            "   c) Local language support and affordability\n",
            "   d) Access to large hospitals\n",
            "\n",
            "‚úÖ Correct Answer: C)\n",
            "üí° Explanation: The study repeatedly highlights the need for solutions that cater to local languages and are affordable for the target market in Tier-2 cities.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 4: According to the validation section, what is a major barrier to mental healthcare access in Tier-2 cities?\n",
            "\n",
            "   a) Lack of smartphone ownership\n",
            "   b) Shortage of qualified professionals and stigma\n",
            "   c) High cost of internet access\n",
            "   d) Lack of government initiatives\n",
            "\n",
            "‚úÖ Correct Answer: B)\n",
            "üí° Explanation: The validation document clearly points to the shortage of professionals and the societal stigma surrounding mental health as significant barriers.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 5: Which of the following is NOT mentioned as a differentiation strategy for the AI-powered personalized meal planning service for chronic patients?\n",
            "\n",
            "   a) Focus on local recipes and ingredients.\n",
            "   b) Integration with major national food delivery apps.\n",
            "   c) Simple mobile or WhatsApp-based interface.\n",
            "   d) Use of generative AI for dynamic meal plan creation.\n",
            "\n",
            "‚úÖ Correct Answer: B)\n",
            "üí° Explanation: The differentiation strategies listed focus on local relevance, ease of access, and AI-driven personalization, not integration with large, potentially expensive, national food delivery platforms.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 6: Based on the provided business plan for the virtual mental health chatbot, what is the intended business model?\n",
            "\n",
            "   a) Strictly free, publicly funded service\n",
            "   b) A purely B2B SaaS model targeting large corporations\n",
            "   c) A freemium model with B2B SaaS options and potential grant funding.\n",
            "   d) A direct-to-consumer paid model relying solely on individual subscriptions.\n",
            "\n",
            "‚úÖ Correct Answer: C)\n",
            "üí° Explanation: The business plan explicitly outlines a freemium model for individual users combined with B2B SaaS options for institutions and potential grant/CSR funding to support the business.\n",
            "--------------------------------------------------\n",
            "\n",
            "üíæ Would you like to save the quiz to a file? (y/n): y\n",
            "‚úÖ Quiz saved to quiz_results.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85b497b7-e7b8-4480-a808-a3045462be46\", \"quiz_results.txt\", 4485)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with sample content from the course document\n",
        "sample_content = \"\"\"\n",
        "Prompt engineering involves designing and refining inputs to language models to achieve desired outputs. In the context of agents, prompt engineering allows for better control over how an agent interacts with the environment and solves specific tasks. This is particularly useful in domains like robotics and conversational AI. By adjusting the structure and content of the prompts, users can enhance an agent's performance on specific tasks.\n",
        "\n",
        "Key aspects of prompt engineering include:\n",
        "- Understanding the model's capabilities and limitations\n",
        "- Crafting clear and specific instructions\n",
        "- Using examples to guide model behavior\n",
        "- Iterative refinement based on outputs\n",
        "- Context management for better results\n",
        "\n",
        "Effective prompt engineering can significantly improve the quality and relevance of AI-generated responses, making it an essential skill for working with language models in various applications.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üß™ Testing with sample content...\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìã SAMPLE SUMMARY:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "summary = study_assistant.summarize_content(sample_content)\n",
        "print(summary)\n",
        "\n",
        "print(\"\\n‚è≥ Generating sample quiz questions...\")\n",
        "questions = study_assistant.generate_quiz_questions(sample_content, 3)\n",
        "\n",
        "if questions:\n",
        "    study_assistant.display_quiz(questions)\n",
        "else:\n",
        "   print(\"‚ùå Failed to generate sample questions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "CFTmxCcfVjPA",
        "outputId": "c8afcc56-2c09-4e34-da70-c774a75da0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing with sample content...\n",
            "\n",
            "============================================================\n",
            "üìã SAMPLE SUMMARY:\n",
            "============================================================\n",
            "* Prompt engineering designs input instructions for language models to get desired outputs.\n",
            "* It's crucial for controlling AI agents in tasks, especially in robotics and conversational AI.\n",
            "* Effective prompts require understanding the model's abilities and weaknesses.\n",
            "* Clear, specific instructions and illustrative examples guide the model's actions.\n",
            "* Iterative refinement based on the model's responses is essential for improvement.\n",
            "* Context is important for better, more relevant results.\n",
            "* Well-crafted prompts significantly enhance AI response quality and relevance.\n",
            "* Prompt engineering is a vital skill for working with language models across applications.\n",
            "\n",
            "\n",
            "‚è≥ Generating sample quiz questions...\n",
            "============================================================\n",
            "üìö GENERATED QUIZ QUESTIONS\n",
            "============================================================\n",
            "\n",
            "üîπ Question 1: What is the primary goal of prompt engineering in the context of AI agents?\n",
            "\n",
            "   a) To increase the speed of the AI agent's processing.\n",
            "   b) To improve the AI agent's interaction with the environment and task completion.\n",
            "   c) To reduce the computational resources used by the AI agent.\n",
            "   d) To make the AI agent more autonomous and independent of user input.\n",
            "\n",
            "‚úÖ Correct Answer: B)\n",
            "üí° Explanation: The passage explicitly states that prompt engineering allows for better control over how an agent interacts with the environment and solves specific tasks.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 2: Which of the following is NOT a key aspect of effective prompt engineering?\n",
            "\n",
            "   a) Understanding the model's capabilities and limitations.\n",
            "   b) Using ambiguous and general instructions.\n",
            "   c) Using examples to guide model behavior.\n",
            "   d) Iterative refinement based on outputs.\n",
            "\n",
            "‚úÖ Correct Answer: B)\n",
            "üí° Explanation: The passage emphasizes clear and specific instructions as a key aspect. Ambiguous instructions would be counterproductive.\n",
            "--------------------------------------------------\n",
            "\n",
            "üîπ Question 3: A robotics engineer is using a language model to control a robot arm. The robot consistently misinterprets instructions about object placement.  What prompt engineering technique would be MOST helpful in addressing this issue?\n",
            "\n",
            "   a) Decreasing the length of the prompts.\n",
            "   b) Providing more examples of correct object placement instructions in the prompt.\n",
            "   c) Using more technical jargon in the prompts.\n",
            "   d) Reducing the frequency of prompts to the robot arm.\n",
            "\n",
            "‚úÖ Correct Answer: B)\n",
            "üí° Explanation: The passage highlights the use of examples to guide model behavior.  Providing more examples of correct instructions would directly address the misinterpretation issue.  The other options are unlikely to improve the accuracy.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}